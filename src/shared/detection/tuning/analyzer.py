"""
Detection Tuning Analyzer

Analyzes detection rule performance and generates HIGH CONFIDENCE recommendations.
"""

import logging
import ipaddress
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional
from enum import Enum
from collections import Counter

from .config import TuningConfig

logger = logging.getLogger(__name__)


class RecommendationType(Enum):
    """Types of tuning recommendations."""
    IP_EXCLUSION = "ip_exclusion"
    USER_EXCLUSION = "user_exclusion"
    THRESHOLD_INCREASE = "threshold_increase"
    THRESHOLD_DECREASE = "threshold_decrease"
    RULE_CONSOLIDATION = "rule_consolidation"
    ZERO_ALERT_WARNING = "zero_alert_warning"
    HIGH_FALSE_POSITIVE = "high_false_positive"


class ConfidenceLevel(Enum):
    """Confidence levels for recommendations."""
    LOW = "low"
    MEDIUM = "medium"
    HIGH = "high"


@dataclass
class TuningRecommendation:
    """A single tuning recommendation."""
    recommendation_id: str
    rule_id: str
    rule_name: str
    recommendation_type: RecommendationType
    confidence: ConfidenceLevel
    title: str
    description: str
    evidence: Dict[str, Any]
    proposed_change: Optional[str] = None
    impact_estimate: Optional[str] = None
    risk_assessment: Optional[str] = None

    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary."""
        return {
            'recommendation_id': self.recommendation_id,
            'rule_id': self.rule_id,
            'rule_name': self.rule_name,
            'recommendation_type': self.recommendation_type.value,
            'confidence': self.confidence.value,
            'title': self.title,
            'description': self.description,
            'evidence': self.evidence,
            'proposed_change': self.proposed_change,
            'impact_estimate': self.impact_estimate,
            'risk_assessment': self.risk_assessment,
        }


@dataclass
class AnalysisResult:
    """Result of analyzing a single rule."""
    rule_id: str
    rule_name: str
    analysis_timestamp: datetime
    alert_count: int
    analysis_window_days: int
    recommendations: List[TuningRecommendation] = field(default_factory=list)
    error: Optional[str] = None
    skipped: bool = False
    skip_reason: Optional[str] = None

    def has_high_confidence_recommendations(self) -> bool:
        """Check if any recommendations are high confidence."""
        return any(r.confidence == ConfidenceLevel.HIGH for r in self.recommendations)

    def get_high_confidence_recommendations(self) -> List[TuningRecommendation]:
        """Get only high confidence recommendations."""
        return [r for r in self.recommendations if r.confidence == ConfidenceLevel.HIGH]

    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary."""
        return {
            'rule_id': self.rule_id,
            'rule_name': self.rule_name,
            'analysis_timestamp': self.analysis_timestamp.isoformat(),
            'alert_count': self.alert_count,
            'analysis_window_days': self.analysis_window_days,
            'recommendations': [r.to_dict() for r in self.recommendations],
            'error': self.error,
            'skipped': self.skipped,
            'skip_reason': self.skip_reason,
        }


class TuningAnalyzer:
    """
    Analyzes detection rules and generates tuning recommendations.

    Only generates HIGH CONFIDENCE recommendations to prevent engineer fatigue.
    """

    # RFC 1918 private IP ranges
    PRIVATE_IP_RANGES = [
        ipaddress.ip_network('10.0.0.0/8'),
        ipaddress.ip_network('172.16.0.0/12'),
        ipaddress.ip_network('192.168.0.0/16'),
        ipaddress.ip_network('127.0.0.0/8'),
    ]

    def __init__(
        self,
        config: Optional[TuningConfig] = None,
        query_executor=None,
        feedback_tracker=None
    ):
        """
        Initialize tuning analyzer.

        Args:
            config: Tuning configuration
            query_executor: Query executor for Athena/BigQuery/Synapse
            feedback_tracker: Feedback tracker for learning from Jira resolutions
        """
        self.config = config or TuningConfig()
        self.query_executor = query_executor
        self.feedback_tracker = feedback_tracker

    def analyze_rule(
        self,
        rule_id: str,
        rule_name: str,
        rule_metadata: Dict[str, Any],
        alerts: List[Dict[str, Any]]
    ) -> AnalysisResult:
        """
        Analyze a single detection rule.

        Args:
            rule_id: Rule identifier
            rule_name: Rule name
            rule_metadata: Rule metadata (tags, severity, etc.)
            alerts: List of alerts generated by this rule

        Returns:
            AnalysisResult with recommendations
        """
        now = datetime.utcnow()
        result = AnalysisResult(
            rule_id=rule_id,
            rule_name=rule_name,
            analysis_timestamp=now,
            alert_count=len(alerts),
            analysis_window_days=self.config.analysis_window_days
        )

        # Check if suppressed by feedback
        if self.feedback_tracker:
            if self.feedback_tracker.is_rule_suppressed(rule_id):
                result.skipped = True
                result.skip_reason = "Rule suppressed due to previous rejections"
                return result

        # Check minimum alerts threshold
        if len(alerts) < self.config.min_alerts_for_analysis:
            # Check for zero-alert warning
            if len(alerts) == 0:
                zero_alert_rec = self._check_zero_alerts(rule_id, rule_name, rule_metadata)
                if zero_alert_rec:
                    result.recommendations.append(zero_alert_rec)
            else:
                result.skipped = True
                result.skip_reason = f"Insufficient alerts ({len(alerts)} < {self.config.min_alerts_for_analysis})"
            return result

        try:
            # Run analysis patterns
            recommendations = []

            # 1. False positive pattern detection
            fp_recs = self._analyze_false_positives(rule_id, rule_name, alerts)
            recommendations.extend(fp_recs)

            # 2. IP-based exclusion analysis
            ip_recs = self._analyze_ip_patterns(rule_id, rule_name, alerts)
            recommendations.extend(ip_recs)

            # 3. User-based exclusion analysis
            user_recs = self._analyze_user_patterns(rule_id, rule_name, alerts)
            recommendations.extend(user_recs)

            # 4. Threshold analysis
            threshold_recs = self._analyze_thresholds(rule_id, rule_name, alerts)
            recommendations.extend(threshold_recs)

            result.recommendations = recommendations

        except Exception as e:
            logger.error(f"Error analyzing rule {rule_id}: {e}")
            result.error = str(e)

        return result

    def _analyze_false_positives(
        self,
        rule_id: str,
        rule_name: str,
        alerts: List[Dict[str, Any]]
    ) -> List[TuningRecommendation]:
        """Analyze for false positive patterns."""
        recommendations = []

        # Group alerts by source
        source_counts = Counter()
        for alert in alerts:
            # Try to identify source (IP, user, service account, etc.)
            source = self._extract_primary_source(alert)
            if source:
                source_counts[source] += 1

        total_alerts = len(alerts)

        # Check if any single source accounts for high percentage
        for source, count in source_counts.most_common(5):
            ratio = count / total_alerts

            if ratio >= self.config.false_positive_rate_threshold:
                # HIGH CONFIDENCE: Single source accounts for 70%+ of alerts
                rec = TuningRecommendation(
                    recommendation_id=f"fp-{rule_id}-{hash(source) % 10000:04d}",
                    rule_id=rule_id,
                    rule_name=rule_name,
                    recommendation_type=RecommendationType.HIGH_FALSE_POSITIVE,
                    confidence=ConfidenceLevel.HIGH,
                    title=f"High false positive rate from {source}",
                    description=(
                        f"Source '{source}' accounts for {ratio*100:.1f}% of all alerts "
                        f"({count} of {total_alerts}). This suggests a potential false positive pattern."
                    ),
                    evidence={
                        'source': source,
                        'alert_count': count,
                        'total_alerts': total_alerts,
                        'percentage': round(ratio * 100, 1),
                        'sample_timestamps': [
                            a.get('timestamp', '')[:19] for a in alerts[:5]
                            if self._extract_primary_source(a) == source
                        ]
                    },
                    proposed_change=f"Add exclusion for source: {source}",
                    impact_estimate=f"Would reduce alerts by approximately {ratio*100:.0f}%",
                    risk_assessment="May miss true positives from this source. Review sample alerts before applying."
                )
                recommendations.append(rec)

        return recommendations

    def _analyze_ip_patterns(
        self,
        rule_id: str,
        rule_name: str,
        alerts: List[Dict[str, Any]]
    ) -> List[TuningRecommendation]:
        """Analyze IP-based patterns for exclusion recommendations."""
        recommendations = []

        # Extract source IPs
        ip_counts = Counter()
        internal_count = 0
        external_count = 0

        for alert in alerts:
            ip = self._extract_ip(alert)
            if ip:
                ip_counts[ip] += 1
                if self._is_internal_ip(ip):
                    internal_count += 1
                else:
                    external_count += 1

        total_with_ip = internal_count + external_count
        if total_with_ip == 0:
            return recommendations

        # Check if internal IPs dominate
        internal_ratio = internal_count / total_with_ip

        if internal_ratio >= self.config.false_positive_rate_threshold:
            # HIGH CONFIDENCE: Internal IPs account for 70%+ of alerts
            rec = TuningRecommendation(
                recommendation_id=f"ip-internal-{rule_id}",
                rule_id=rule_id,
                rule_name=rule_name,
                recommendation_type=RecommendationType.IP_EXCLUSION,
                confidence=ConfidenceLevel.HIGH,
                title="High alert rate from internal IP ranges",
                description=(
                    f"Internal IP addresses (RFC 1918) account for {internal_ratio*100:.1f}% of alerts "
                    f"({internal_count} of {total_with_ip}). Consider excluding internal IP ranges."
                ),
                evidence={
                    'internal_count': internal_count,
                    'external_count': external_count,
                    'total_with_ip': total_with_ip,
                    'percentage': round(internal_ratio * 100, 1),
                    'top_internal_ips': [
                        ip for ip, _ in ip_counts.most_common(10)
                        if self._is_internal_ip(ip)
                    ][:5]
                },
                proposed_change=(
                    "Add filter to exclude internal IP ranges:\n"
                    "  filter_internal:\n"
                    "    sourceIPAddress|startswith:\n"
                    "      - '10.'\n"
                    "      - '172.16.'\n"
                    "      - '192.168.'"
                ),
                impact_estimate=f"Would reduce alerts by approximately {internal_ratio*100:.0f}%",
                risk_assessment="May miss insider threat activity from internal network."
            )
            recommendations.append(rec)

        # Check for single IP dominating
        for ip, count in ip_counts.most_common(3):
            ratio = count / total_with_ip
            if ratio >= self.config.false_positive_rate_threshold:
                rec = TuningRecommendation(
                    recommendation_id=f"ip-single-{rule_id}-{hash(ip) % 10000:04d}",
                    rule_id=rule_id,
                    rule_name=rule_name,
                    recommendation_type=RecommendationType.IP_EXCLUSION,
                    confidence=ConfidenceLevel.HIGH,
                    title=f"Single IP {ip} dominates alerts",
                    description=(
                        f"IP address {ip} accounts for {ratio*100:.1f}% of alerts "
                        f"({count} of {total_with_ip}). This may be a known-good service or scanner."
                    ),
                    evidence={
                        'ip': ip,
                        'alert_count': count,
                        'total_alerts': total_with_ip,
                        'percentage': round(ratio * 100, 1),
                        'is_internal': self._is_internal_ip(ip)
                    },
                    proposed_change=f"Add exclusion for IP: {ip}",
                    impact_estimate=f"Would reduce alerts by approximately {ratio*100:.0f}%"
                )
                recommendations.append(rec)

        return recommendations

    def _analyze_user_patterns(
        self,
        rule_id: str,
        rule_name: str,
        alerts: List[Dict[str, Any]]
    ) -> List[TuningRecommendation]:
        """Analyze user-based patterns for exclusion recommendations."""
        recommendations = []

        # Extract users
        user_counts = Counter()
        service_account_count = 0

        for alert in alerts:
            user = self._extract_user(alert)
            if user:
                user_counts[user] += 1
                if self._is_service_account(user):
                    service_account_count += 1

        total_with_user = sum(user_counts.values())
        if total_with_user == 0:
            return recommendations

        # Check if service accounts dominate
        service_ratio = service_account_count / total_with_user

        if service_ratio >= self.config.false_positive_rate_threshold:
            # Get top service accounts
            service_accounts = [
                user for user, _ in user_counts.most_common(10)
                if self._is_service_account(user)
            ][:5]

            rec = TuningRecommendation(
                recommendation_id=f"user-service-{rule_id}",
                rule_id=rule_id,
                rule_name=rule_name,
                recommendation_type=RecommendationType.USER_EXCLUSION,
                confidence=ConfidenceLevel.HIGH,
                title="High alert rate from service accounts",
                description=(
                    f"Service accounts account for {service_ratio*100:.1f}% of alerts "
                    f"({service_account_count} of {total_with_user}). These may be expected automation."
                ),
                evidence={
                    'service_account_count': service_account_count,
                    'total_with_user': total_with_user,
                    'percentage': round(service_ratio * 100, 1),
                    'top_service_accounts': service_accounts
                },
                proposed_change=f"Add exclusion for service accounts: {', '.join(service_accounts)}",
                impact_estimate=f"Would reduce alerts by approximately {service_ratio*100:.0f}%",
                risk_assessment="Service account compromise is a real threat. Ensure these are expected activities."
            )
            recommendations.append(rec)

        # Check for single user dominating
        for user, count in user_counts.most_common(3):
            ratio = count / total_with_user
            if ratio >= self.config.false_positive_rate_threshold:
                rec = TuningRecommendation(
                    recommendation_id=f"user-single-{rule_id}-{hash(user) % 10000:04d}",
                    rule_id=rule_id,
                    rule_name=rule_name,
                    recommendation_type=RecommendationType.USER_EXCLUSION,
                    confidence=ConfidenceLevel.HIGH,
                    title=f"Single user '{user}' dominates alerts",
                    description=(
                        f"User '{user}' accounts for {ratio*100:.1f}% of alerts "
                        f"({count} of {total_with_user}). This may indicate expected activity or a repeat offender."
                    ),
                    evidence={
                        'user': user,
                        'alert_count': count,
                        'total_alerts': total_with_user,
                        'percentage': round(ratio * 100, 1),
                        'is_service_account': self._is_service_account(user)
                    },
                    proposed_change=f"Add exclusion for user: {user}",
                    impact_estimate=f"Would reduce alerts by approximately {ratio*100:.0f}%"
                )
                recommendations.append(rec)

        return recommendations

    def _analyze_thresholds(
        self,
        rule_id: str,
        rule_name: str,
        alerts: List[Dict[str, Any]]
    ) -> List[TuningRecommendation]:
        """Analyze if threshold adjustments are needed."""
        recommendations = []

        # Calculate daily alert counts
        daily_counts = Counter()
        for alert in alerts:
            timestamp = alert.get('timestamp', '')
            if timestamp:
                date = timestamp[:10]  # YYYY-MM-DD
                daily_counts[date] += 1

        if len(daily_counts) < 7:
            return recommendations  # Need at least a week of data

        counts = list(daily_counts.values())
        avg_daily = sum(counts) / len(counts)

        # Calculate standard deviation
        if len(counts) > 1:
            variance = sum((x - avg_daily) ** 2 for x in counts) / len(counts)
            std_dev = variance ** 0.5
        else:
            std_dev = 0

        # Check for high variance (might need threshold adjustment)
        if avg_daily > 10 and std_dev > 0:
            max_daily = max(counts)
            z_score = (max_daily - avg_daily) / std_dev if std_dev > 0 else 0

            if z_score >= self.config.threshold_deviation_stddev:
                # HIGH CONFIDENCE: Significant deviation suggests threshold issues
                rec = TuningRecommendation(
                    recommendation_id=f"threshold-{rule_id}",
                    rule_id=rule_id,
                    rule_name=rule_name,
                    recommendation_type=RecommendationType.THRESHOLD_INCREASE,
                    confidence=ConfidenceLevel.HIGH,
                    title="High alert volume variance suggests threshold adjustment",
                    description=(
                        f"Alert volume varies significantly (avg: {avg_daily:.1f}/day, "
                        f"max: {max_daily}/day, std dev: {std_dev:.1f}). "
                        f"Consider increasing detection threshold to reduce noise."
                    ),
                    evidence={
                        'avg_daily': round(avg_daily, 1),
                        'max_daily': max_daily,
                        'std_dev': round(std_dev, 1),
                        'z_score': round(z_score, 2),
                        'total_days': len(daily_counts),
                        'total_alerts': sum(counts)
                    },
                    proposed_change="Increase detection threshold by 50% or adjust timeframe",
                    impact_estimate="Would reduce alert volume during peak periods"
                )
                recommendations.append(rec)

        return recommendations

    def _check_zero_alerts(
        self,
        rule_id: str,
        rule_name: str,
        rule_metadata: Dict[str, Any]
    ) -> Optional[TuningRecommendation]:
        """Check if a zero-alert rule should be flagged."""
        # Only flag if rule has been enabled for sufficient time
        enabled_date = rule_metadata.get('enabled_date')
        if enabled_date:
            try:
                enabled_dt = datetime.fromisoformat(enabled_date.replace('Z', ''))
                days_enabled = (datetime.utcnow() - enabled_dt).days

                if days_enabled >= self.config.zero_alert_warning_days:
                    return TuningRecommendation(
                        recommendation_id=f"zero-{rule_id}",
                        rule_id=rule_id,
                        rule_name=rule_name,
                        recommendation_type=RecommendationType.ZERO_ALERT_WARNING,
                        confidence=ConfidenceLevel.HIGH,
                        title="Detection rule has not triggered in 30+ days",
                        description=(
                            f"Rule '{rule_name}' has been enabled for {days_enabled} days "
                            f"but has not generated any alerts. This may indicate the rule "
                            f"is not matching expected patterns or the threat is not present."
                        ),
                        evidence={
                            'days_enabled': days_enabled,
                            'alert_count': 0,
                            'enabled_date': enabled_date
                        },
                        proposed_change="Review rule logic or consider disabling if not applicable",
                        risk_assessment="Rule may be providing false sense of coverage."
                    )
            except (ValueError, TypeError):
                pass

        return None

    def _extract_primary_source(self, alert: Dict[str, Any]) -> Optional[str]:
        """Extract primary source identifier from alert."""
        # Try user first, then IP
        user = self._extract_user(alert)
        if user:
            return f"user:{user}"

        ip = self._extract_ip(alert)
        if ip:
            return f"ip:{ip}"

        return None

    def _extract_ip(self, alert: Dict[str, Any]) -> Optional[str]:
        """Extract source IP from alert."""
        for key in ['sourceIPAddress', 'source_ip', 'srcaddr', 'src_ip', 'ip']:
            if key in alert and alert[key]:
                return alert[key]

        # Check nested structures
        if 'event' in alert and isinstance(alert['event'], dict):
            return self._extract_ip(alert['event'])

        return None

    def _extract_user(self, alert: Dict[str, Any]) -> Optional[str]:
        """Extract user from alert."""
        for key in ['userName', 'user', 'principalId', 'userIdentity']:
            if key in alert:
                value = alert[key]
                if isinstance(value, str):
                    return value
                elif isinstance(value, dict):
                    return value.get('userName') or value.get('principalId')

        return None

    def _is_internal_ip(self, ip: str) -> bool:
        """Check if IP is internal/private."""
        try:
            ip_obj = ipaddress.ip_address(ip)
            return any(ip_obj in network for network in self.PRIVATE_IP_RANGES)
        except ValueError:
            return False

    def _is_service_account(self, user: str) -> bool:
        """Check if user appears to be a service account."""
        if not user:
            return False

        user_lower = user.lower()

        # Common service account patterns
        service_patterns = [
            'service', 'svc', 'bot', 'automation', 'system',
            'lambda', 'ecs', 'codebuild', 'codepipeline',
            'cloudformation', 'terraform', 'jenkins', 'github',
            'datadog', 'sumologic', 'splunk', 'newrelic'
        ]

        for pattern in service_patterns:
            if pattern in user_lower:
                return True

        # Check for AWS service roles
        if user.startswith('arn:aws:') and ':role/' in user:
            return True

        return False

    def generate_jira_ticket_body(
        self,
        analysis_result: AnalysisResult,
        recommendation: TuningRecommendation
    ) -> Dict[str, str]:
        """
        Generate Jira ticket content for a recommendation.

        Args:
            analysis_result: Full analysis result
            recommendation: Specific recommendation to create ticket for

        Returns:
            Dictionary with 'summary' and 'description' for Jira
        """
        summary = f"[Detection Tuning] {analysis_result.rule_name} - {recommendation.title}"

        # Build description
        description_parts = [
            "h2. Analysis Summary",
            "",
            f"*Rule:* {analysis_result.rule_name} ({analysis_result.rule_id})",
            f"*Analysis Period:* {analysis_result.analysis_window_days} days",
            f"*Total Alerts:* {analysis_result.alert_count}",
            f"*Analysis Date:* {analysis_result.analysis_timestamp.strftime('%Y-%m-%d')}",
            "",
            "h2. Finding",
            "",
            f"*Type:* {recommendation.recommendation_type.value.replace('_', ' ').title()}",
            f"*Confidence:* {recommendation.confidence.value.upper()}",
            "",
            recommendation.description,
            "",
            "h2. Evidence",
            "",
        ]

        # Add evidence as formatted list
        for key, value in recommendation.evidence.items():
            if isinstance(value, list):
                value_str = ', '.join(str(v) for v in value[:5])
                if len(value) > 5:
                    value_str += f" (and {len(value) - 5} more)"
            else:
                value_str = str(value)
            description_parts.append(f"* *{key.replace('_', ' ').title()}:* {value_str}")

        description_parts.extend([
            "",
            "h2. Recommendation",
            "",
            recommendation.proposed_change or "Review and adjust rule accordingly.",
            "",
        ])

        if recommendation.impact_estimate:
            description_parts.extend([
                "h2. Impact Estimate",
                "",
                recommendation.impact_estimate,
                "",
            ])

        if recommendation.risk_assessment:
            description_parts.extend([
                "h2. Risk Assessment",
                "",
                recommendation.risk_assessment,
                "",
            ])

        description_parts.extend([
            "h2. Next Steps",
            "",
            "# Review the analysis above",
            "# Verify the finding with sample alerts",
            "# Update the Sigma rule file if appropriate",
            "# Test the updated rule before deploying",
            "",
            "----",
            f"_Generated by Mantissa Log Self-Learning Detection Engineer_",
            f"_Recommendation ID: {recommendation.recommendation_id}_",
        ])

        return {
            'summary': summary[:255],  # Jira summary limit
            'description': '\n'.join(description_parts)
        }
